{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7KE5+PW90SZi6Vb7y+Ihf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKitsopanos/COMPUTATIONALINTELLIGENCEPERSONAL/blob/main/COMPUTATIONAL_INTELLIGENCE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyDiRW20Sa4P",
        "outputId": "e1dc40e2-e250-4e68-cd05-474fceb3ea2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COMPUTATIONALINTELLIGENCEPERSONAL'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 109 (delta 54), reused 105 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (109/109), 194.65 KiB | 19.46 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JKitsopanos/COMPUTATIONALINTELLIGENCEPERSONAL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/COMPUTATIONALINTELLIGENCEPERSONAL\")\n",
        "os.listdir()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cr97spwTTMb",
        "outputId": "83e4777b-5818-4f1d-c15b-b7a243f99753"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['COMPUTATIONALINTELLIGENCEPERSONAL',\n",
              " 'references.bib',\n",
              " 'additional files',\n",
              " 'loss_function.py',\n",
              " 'base.pt',\n",
              " 'sgd.pt',\n",
              " 'main.py',\n",
              " 'figures',\n",
              " 'sgd.py',\n",
              " '__pycache__',\n",
              " 'cso.py',\n",
              " 'requirements_gpu.txt',\n",
              " 'data',\n",
              " 'visualisation.py',\n",
              " 'Makefile',\n",
              " 'requirements.txt',\n",
              " 'nsgaII.py',\n",
              " '.gitignore',\n",
              " 'readme.md',\n",
              " '.git',\n",
              " 'sqn.py',\n",
              " 'de.py',\n",
              " 'report.tex',\n",
              " 'COMPUTATIONAL_INTELLIGENCE_COURSEWORK.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements_gpu.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljVzv-6jTWpM",
        "outputId": "0ad165c6-92a5-4cfd-94d1-6a878731b048"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contourpy==1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 2)) (0.12.1)\n",
            "Collecting filelock==3.19.1 (from -r requirements_gpu.txt (line 3))\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: fonttools==4.60.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 4)) (4.60.1)\n",
            "Collecting fsspec==2025.9.0 (from -r requirements_gpu.txt (line 5))\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: kiwisolver==1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 7)) (1.4.9)\n",
            "Collecting MarkupSafe==2.1.5 (from -r requirements_gpu.txt (line 8))\n",
            "  Using cached MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib==3.10.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 9)) (3.10.7)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 11)) (3.5)\n",
            "Collecting numpy==2.3.3 (from -r requirements_gpu.txt (line 12))\n",
            "  Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: packaging==25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 13)) (25.0)\n",
            "Collecting pillow==11.3.0 (from -r requirements_gpu.txt (line 14))\n",
            "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pyparsing==3.2.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 15)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 16)) (2.9.0.post0)\n",
            "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_gpu.txt (line 17)) (1.17.0)\n",
            "Collecting sympy==1.13.1 (from -r requirements_gpu.txt (line 18))\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.5.1+cu121 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.5.1+cu121\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkRpN6hmTZ3o",
        "outputId": "dc5444be-332e-4018-98fb-f361573babe8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contourpy==1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: filelock==3.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.20.0)\n",
            "Requirement already satisfied: fonttools==4.60.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.60.1)\n",
            "Requirement already satisfied: fsspec==2025.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2025.10.0)\n",
            "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: kiwisolver==1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.4.9)\n",
            "Requirement already satisfied: MarkupSafe==3.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.0.3)\n",
            "Requirement already satisfied: matplotlib==3.10.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (3.10.7)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.5)\n",
            "Requirement already satisfied: numpy==2.3.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.3.4)\n",
            "Requirement already satisfied: packaging==25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (25.0)\n",
            "Requirement already satisfied: pillow==12.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (12.0.0)\n",
            "Requirement already satisfied: pyparsing==3.2.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (2.9.0.post0)\n",
            "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (1.17.0)\n",
            "Requirement already satisfied: sympy==1.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.14.0)\n",
            "Requirement already satisfied: torch==2.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (2.9.1)\n",
            "Requirement already satisfied: torchvision==0.24.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (0.24.1)\n",
            "Requirement already satisfied: typing_extensions==4.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 19)) (3.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "id": "gu_8WyDMTeOD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --some-argument value"
      ],
      "metadata": {
        "id": "PSzIYk6-T_QL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -R \"base.pt\" -n ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFw_KJEfVp78",
        "outputId": "74dd6720-9d79-4386-c0bc-f1b0001c82a4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./COMPUTATIONALINTELLIGENCEPERSONAL/sgd.py:76:    torch.save(network, \"base.pt\")\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/sgd.py:78:    print(\"Saved frozen model with unfrozen fc3. Resetted fc3 parameters and stored in 'base.pt.'\")\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/cso.py:184:base = torch.load(\"base.pt\", weights_only=False)\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/nsgaII.py:150:    print(\"Loading base.pt for NSGA-II optimisation\")\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/nsgaII.py:151:    network = torch.load(\"base.pt\", map_location=device)\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/sqn.py:17:base = torch.load(\"base.pt\", weights_only=False)\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/de.py:17:base_model = torch.load(\"base.pt\", weights_only=False)\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/de.py:109:base = torch.load(\"base.pt\", weights_only=False)\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/COMPUTATIONAL_INTELLIGENCE_COURSEWORK.ipynb:919:            \"Saved frozen model with unfrozen fc3. Resetted fc3 parameters and stored in 'base.pt.'\\n\"\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/COMPUTATIONAL_INTELLIGENCE_COURSEWORK.ipynb:946:              \" 'base.pt',\\n\",\n",
            "./COMPUTATIONALINTELLIGENCEPERSONAL/COMPUTATIONAL_INTELLIGENCE_COURSEWORK.ipynb:1645:            \"Saved frozen model with unfrozen fc3. Resetted fc3 parameters and stored in 'base.pt.'\\n\"\n",
            "./sgd.py:76:    torch.save(network, \"base.pt\")\n",
            "./sgd.py:78:    print(\"Saved frozen model with unfrozen fc3. Resetted fc3 parameters and stored in 'base.pt.'\")\n",
            "./cso.py:184:base = torch.load(\"base.pt\", weights_only=False)\n",
            "./nsgaII.py:188:    print(\"Loading base.pt for NSGA-II optimisation\")\n",
            "./nsgaII.py:189:    network = torch.load(\"base.pt\", map_location=device)\n",
            "./sqn.py:17:base = torch.load(\"base.pt\", weights_only=False)\n",
            "./de.py:17:base_model = torch.load(\"base.pt\", weights_only=False)\n",
            "./de.py:109:base = torch.load(\"base.pt\", weights_only=False)\n",
            "./COMPUTATIONAL_INTELLIGENCE_COURSEWORK.ipynb:919:            \"Saved frozen model with unfrozen fc3. Resetted fc3 parameters and stored in 'base.pt.'\\n\"\n",
            "./COMPUTATIONAL_INTELLIGENCE_COURSEWORK.ipynb:946:              \" 'base.pt',\\n\",\n",
            "./COMPUTATIONAL_INTELLIGENCE_COURSEWORK.ipynb:1645:            \"Saved frozen model with unfrozen fc3. Resetted fc3 parameters and stored in 'base.pt.'\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python de.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3lAjpBPUCHB",
        "outputId": "61e18224-9548-4d4f-de0c-bba8c326476f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=8192, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n",
            "0\tTraceback (most recent call last):\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/de.py\", line 113, in <module>\n",
            "    print(train(base, 0.5, 0.5, POPULATION_SIZE, 1))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/de.py\", line 98, in train\n",
            "    print(loss_function(get_best(population)))\n",
            "                        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/de.py\", line 80, in get_best\n",
            "    return min(population, key=loss_function)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/loss_function.py\", line 159, in f\n",
            "    return loss_function(individual, base_model)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/loss_function.py\", line 128, in loss_function\n",
            "    return _loss_function(base_model)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/loss_function.py\", line 101, in _loss_function\n",
            "    loss_val, _ = eval_loss_and_acc(model)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/loss_function.py\", line 78, in eval_loss_and_acc\n",
            "    assert next(model.parameters()).device == device, \"Model not on correct device.\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: Model not on correct device.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python cso.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDbTLBr-UFTr",
        "outputId": "5a47f2be-d8b1-4515-bd51-15b433043007"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/cso.py\", line 192, in <module>\n",
            "    population_size=POPULATION_SIZE,\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "NameError: name 'POPULATION_SIZE' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python nsgaII.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84rd7DhMUH7h",
        "outputId": "01b8d964-2202-4c5f-ef1c-d86ca950ec22"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading base.pt for NSGA-II optimisation\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/nsgaII.py\", line 189, in <module>\n",
            "    network = torch.load(\"base.pt\", map_location=device)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1529, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL main.CNN was not an allowed global by default. Please use `torch.serialization.add_safe_globals([main.CNN])` or the `torch.serialization.safe_globals([main.CNN])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python loss_function.py"
      ],
      "metadata": {
        "id": "a2W0qZpqUK4V"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python visualisation.py"
      ],
      "metadata": {
        "id": "LAM2x6rmUSJ7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L-MnwQ_Uyyd",
        "outputId": "5b3904f1-f199-4290-e103-0a92f2a3c78d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deap) (2.3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python nsgaII.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "496mf19YU1wK",
        "outputId": "8b1714aa-4cc7-49dd-fecc-685bfb661e63"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading base.pt for NSGA-II optimisation\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/COMPUTATIONALINTELLIGENCEPERSONAL/nsgaII.py\", line 189, in <module>\n",
            "    network = torch.load(\"base.pt\", map_location=device)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1529, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL main.CNN was not an allowed global by default. Please use `torch.serialization.add_safe_globals([main.CNN])` or the `torch.serialization.safe_globals([main.CNN])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sgd.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NNJSyUNVuRZ",
        "outputId": "dca3a453-fa12-4aaa-f137-5bdea902600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Starting training\n",
            "\n",
            "Epoch [1/10], Step [200/12500], Loss: 2.2904\n",
            "Epoch [1/10], Step [400/12500], Loss: 2.2626\n",
            "Epoch [1/10], Step [600/12500], Loss: 2.1574\n",
            "Epoch [1/10], Step [800/12500], Loss: 2.0631\n",
            "Epoch [1/10], Step [1000/12500], Loss: 1.9757\n",
            "Epoch [1/10], Step [1200/12500], Loss: 1.9811\n",
            "Epoch [1/10], Step [1400/12500], Loss: 1.8530\n",
            "Epoch [1/10], Step [1600/12500], Loss: 1.8128\n",
            "Epoch [1/10], Step [1800/12500], Loss: 1.7873\n",
            "Epoch [1/10], Step [2000/12500], Loss: 1.7538\n",
            "Epoch [1/10], Step [2200/12500], Loss: 1.6485\n",
            "Epoch [1/10], Step [2400/12500], Loss: 1.7550\n",
            "Epoch [1/10], Step [2600/12500], Loss: 1.6450\n",
            "Epoch [1/10], Step [2800/12500], Loss: 1.6389\n",
            "Epoch [1/10], Step [3000/12500], Loss: 1.6196\n",
            "Epoch [1/10], Step [3200/12500], Loss: 1.5821\n",
            "Epoch [1/10], Step [3400/12500], Loss: 1.6111\n",
            "Epoch [1/10], Step [3600/12500], Loss: 1.4515\n",
            "Epoch [1/10], Step [3800/12500], Loss: 1.5273\n",
            "Epoch [1/10], Step [4000/12500], Loss: 1.5261\n",
            "Epoch [1/10], Step [4200/12500], Loss: 1.4762\n",
            "Epoch [1/10], Step [4400/12500], Loss: 1.4425\n",
            "Epoch [1/10], Step [4600/12500], Loss: 1.4339\n",
            "Epoch [1/10], Step [4800/12500], Loss: 1.4736\n",
            "Epoch [1/10], Step [5000/12500], Loss: 1.4234\n",
            "Epoch [1/10], Step [5200/12500], Loss: 1.4293\n",
            "Epoch [1/10], Step [5400/12500], Loss: 1.4222\n",
            "Epoch [1/10], Step [5600/12500], Loss: 1.3949\n",
            "Epoch [1/10], Step [5800/12500], Loss: 1.3808\n",
            "Epoch [1/10], Step [6000/12500], Loss: 1.3887\n",
            "Epoch [1/10], Step [6200/12500], Loss: 1.3808\n",
            "Epoch [1/10], Step [6400/12500], Loss: 1.3741\n",
            "Epoch [1/10], Step [6600/12500], Loss: 1.3459\n",
            "Epoch [1/10], Step [6800/12500], Loss: 1.3934\n",
            "Epoch [1/10], Step [7000/12500], Loss: 1.3534\n",
            "Epoch [1/10], Step [7200/12500], Loss: 1.2649\n",
            "Epoch [1/10], Step [7400/12500], Loss: 1.2559\n",
            "Epoch [1/10], Step [7600/12500], Loss: 1.3197\n",
            "Epoch [1/10], Step [7800/12500], Loss: 1.3452\n",
            "Epoch [1/10], Step [8000/12500], Loss: 1.3033\n",
            "Epoch [1/10], Step [8200/12500], Loss: 1.3103\n",
            "Epoch [1/10], Step [8400/12500], Loss: 1.2868\n",
            "Epoch [1/10], Step [8600/12500], Loss: 1.2498\n",
            "Epoch [1/10], Step [8800/12500], Loss: 1.2141\n",
            "Epoch [1/10], Step [9000/12500], Loss: 1.2326\n",
            "Epoch [1/10], Step [9200/12500], Loss: 1.2018\n",
            "Epoch [1/10], Step [9400/12500], Loss: 1.2616\n",
            "Epoch [1/10], Step [9600/12500], Loss: 1.2325\n",
            "Epoch [1/10], Step [9800/12500], Loss: 1.1705\n",
            "Epoch [1/10], Step [10000/12500], Loss: 1.1797\n",
            "Epoch [1/10], Step [10200/12500], Loss: 1.1896\n",
            "Epoch [1/10], Step [10400/12500], Loss: 1.1643\n",
            "Epoch [1/10], Step [10600/12500], Loss: 1.1203\n",
            "Epoch [1/10], Step [10800/12500], Loss: 1.1024\n",
            "Epoch [1/10], Step [11000/12500], Loss: 1.0960\n",
            "Epoch [1/10], Step [11200/12500], Loss: 1.1390\n",
            "Epoch [1/10], Step [11400/12500], Loss: 1.1191\n",
            "Epoch [1/10], Step [11600/12500], Loss: 1.1658\n",
            "Epoch [1/10], Step [11800/12500], Loss: 1.0825\n",
            "Epoch [1/10], Step [12000/12500], Loss: 1.1858\n",
            "Epoch [1/10], Step [12200/12500], Loss: 1.1481\n",
            "Epoch [1/10], Step [12400/12500], Loss: 1.1157\n",
            "Epoch [2/10], Step [200/12500], Loss: 1.0270\n",
            "Epoch [2/10], Step [400/12500], Loss: 1.0441\n",
            "Epoch [2/10], Step [600/12500], Loss: 1.0204\n",
            "Epoch [2/10], Step [800/12500], Loss: 1.0758\n",
            "Epoch [2/10], Step [1000/12500], Loss: 1.0164\n",
            "Epoch [2/10], Step [1200/12500], Loss: 1.0161\n",
            "Epoch [2/10], Step [1400/12500], Loss: 1.0985\n",
            "Epoch [2/10], Step [1600/12500], Loss: 1.0621\n",
            "Epoch [2/10], Step [1800/12500], Loss: 1.0280\n",
            "Epoch [2/10], Step [2000/12500], Loss: 1.0461\n",
            "Epoch [2/10], Step [2200/12500], Loss: 1.0245\n",
            "Epoch [2/10], Step [2400/12500], Loss: 1.0094\n",
            "Epoch [2/10], Step [2600/12500], Loss: 0.9759\n",
            "Epoch [2/10], Step [2800/12500], Loss: 0.9458\n",
            "Epoch [2/10], Step [3000/12500], Loss: 0.9247\n",
            "Epoch [2/10], Step [3200/12500], Loss: 1.0508\n",
            "Epoch [2/10], Step [3400/12500], Loss: 0.9721\n",
            "Epoch [2/10], Step [3600/12500], Loss: 0.9439\n",
            "Epoch [2/10], Step [3800/12500], Loss: 1.0205\n",
            "Epoch [2/10], Step [4000/12500], Loss: 0.9099\n",
            "Epoch [2/10], Step [4200/12500], Loss: 1.0431\n",
            "Epoch [2/10], Step [4400/12500], Loss: 0.9077\n",
            "Epoch [2/10], Step [4600/12500], Loss: 0.9570\n",
            "Epoch [2/10], Step [4800/12500], Loss: 0.9651\n",
            "Epoch [2/10], Step [5000/12500], Loss: 0.8788\n",
            "Epoch [2/10], Step [5200/12500], Loss: 0.9934\n",
            "Epoch [2/10], Step [5400/12500], Loss: 0.8998\n",
            "Epoch [2/10], Step [5600/12500], Loss: 0.9437\n",
            "Epoch [2/10], Step [5800/12500], Loss: 0.8818\n",
            "Epoch [2/10], Step [6000/12500], Loss: 0.9719\n",
            "Epoch [2/10], Step [6200/12500], Loss: 0.9288\n",
            "Epoch [2/10], Step [6400/12500], Loss: 0.9947\n",
            "Epoch [2/10], Step [6600/12500], Loss: 0.9132\n",
            "Epoch [2/10], Step [6800/12500], Loss: 0.9875\n",
            "Epoch [2/10], Step [7000/12500], Loss: 1.0167\n",
            "Epoch [2/10], Step [7200/12500], Loss: 0.9028\n",
            "Epoch [2/10], Step [7400/12500], Loss: 0.9313\n",
            "Epoch [2/10], Step [7600/12500], Loss: 0.8010\n",
            "Epoch [2/10], Step [7800/12500], Loss: 0.9311\n",
            "Epoch [2/10], Step [8000/12500], Loss: 0.8710\n",
            "Epoch [2/10], Step [8200/12500], Loss: 0.9497\n",
            "Epoch [2/10], Step [8400/12500], Loss: 0.9380\n",
            "Epoch [2/10], Step [8600/12500], Loss: 0.8631\n",
            "Epoch [2/10], Step [8800/12500], Loss: 0.9065\n",
            "Epoch [2/10], Step [9000/12500], Loss: 0.9011\n",
            "Epoch [2/10], Step [9200/12500], Loss: 0.9267\n",
            "Epoch [2/10], Step [9400/12500], Loss: 0.9169\n",
            "Epoch [2/10], Step [9600/12500], Loss: 0.9283\n",
            "Epoch [2/10], Step [9800/12500], Loss: 0.9415\n",
            "Epoch [2/10], Step [10000/12500], Loss: 0.8849\n",
            "Epoch [2/10], Step [10200/12500], Loss: 0.9273\n",
            "Epoch [2/10], Step [10400/12500], Loss: 0.8999\n",
            "Epoch [2/10], Step [10600/12500], Loss: 0.8573\n",
            "Epoch [2/10], Step [10800/12500], Loss: 0.8009\n",
            "Epoch [2/10], Step [11000/12500], Loss: 0.8870\n",
            "Epoch [2/10], Step [11200/12500], Loss: 0.9163\n",
            "Epoch [2/10], Step [11400/12500], Loss: 0.8901\n",
            "Epoch [2/10], Step [11600/12500], Loss: 0.8190\n",
            "Epoch [2/10], Step [11800/12500], Loss: 0.8681\n",
            "Epoch [2/10], Step [12000/12500], Loss: 0.8591\n",
            "Epoch [2/10], Step [12200/12500], Loss: 0.9172\n",
            "Epoch [2/10], Step [12400/12500], Loss: 0.8547\n",
            "Epoch [3/10], Step [200/12500], Loss: 0.7371\n",
            "Epoch [3/10], Step [400/12500], Loss: 0.7732\n",
            "Epoch [3/10], Step [600/12500], Loss: 0.7298\n",
            "Epoch [3/10], Step [800/12500], Loss: 0.6510\n",
            "Epoch [3/10], Step [1000/12500], Loss: 0.7571\n",
            "Epoch [3/10], Step [1200/12500], Loss: 0.6645\n",
            "Epoch [3/10], Step [1400/12500], Loss: 0.6717\n",
            "Epoch [3/10], Step [1600/12500], Loss: 0.7394\n",
            "Epoch [3/10], Step [1800/12500], Loss: 0.7321\n",
            "Epoch [3/10], Step [2000/12500], Loss: 0.7674\n",
            "Epoch [3/10], Step [2200/12500], Loss: 0.7286\n",
            "Epoch [3/10], Step [2400/12500], Loss: 0.7016\n",
            "Epoch [3/10], Step [2600/12500], Loss: 0.7589\n",
            "Epoch [3/10], Step [2800/12500], Loss: 0.6992\n",
            "Epoch [3/10], Step [3000/12500], Loss: 0.7788\n",
            "Epoch [3/10], Step [3200/12500], Loss: 0.6892\n",
            "Epoch [3/10], Step [3400/12500], Loss: 0.6998\n",
            "Epoch [3/10], Step [3600/12500], Loss: 0.7560\n",
            "Epoch [3/10], Step [3800/12500], Loss: 0.7099\n",
            "Epoch [3/10], Step [4000/12500], Loss: 0.7520\n",
            "Epoch [3/10], Step [4200/12500], Loss: 0.6853\n",
            "Epoch [3/10], Step [4400/12500], Loss: 0.7078\n",
            "Epoch [3/10], Step [4600/12500], Loss: 0.7439\n",
            "Epoch [3/10], Step [4800/12500], Loss: 0.7183\n",
            "Epoch [3/10], Step [5000/12500], Loss: 0.7093\n",
            "Epoch [3/10], Step [5200/12500], Loss: 0.7403\n",
            "Epoch [3/10], Step [5400/12500], Loss: 0.7099\n",
            "Epoch [3/10], Step [5600/12500], Loss: 0.7059\n",
            "Epoch [3/10], Step [5800/12500], Loss: 0.7142\n",
            "Epoch [3/10], Step [6000/12500], Loss: 0.7021\n",
            "Epoch [3/10], Step [6200/12500], Loss: 0.7454\n",
            "Epoch [3/10], Step [6400/12500], Loss: 0.7270\n",
            "Epoch [3/10], Step [6600/12500], Loss: 0.7065\n",
            "Epoch [3/10], Step [6800/12500], Loss: 0.7529\n",
            "Epoch [3/10], Step [7000/12500], Loss: 0.7514\n",
            "Epoch [3/10], Step [7200/12500], Loss: 0.7160\n",
            "Epoch [3/10], Step [7400/12500], Loss: 0.6303\n",
            "Epoch [3/10], Step [7600/12500], Loss: 0.7301\n",
            "Epoch [3/10], Step [7800/12500], Loss: 0.7392\n",
            "Epoch [3/10], Step [8000/12500], Loss: 0.7370\n",
            "Epoch [3/10], Step [8200/12500], Loss: 0.6943\n",
            "Epoch [3/10], Step [8400/12500], Loss: 0.7100\n",
            "Epoch [3/10], Step [8600/12500], Loss: 0.7445\n",
            "Epoch [3/10], Step [8800/12500], Loss: 0.7022\n",
            "Epoch [3/10], Step [9000/12500], Loss: 0.7215\n",
            "Epoch [3/10], Step [9200/12500], Loss: 0.6850\n",
            "Epoch [3/10], Step [9400/12500], Loss: 0.7362\n",
            "Epoch [3/10], Step [9600/12500], Loss: 0.7031\n",
            "Epoch [3/10], Step [9800/12500], Loss: 0.6875\n",
            "Epoch [3/10], Step [10000/12500], Loss: 0.7000\n",
            "Epoch [3/10], Step [10200/12500], Loss: 0.7221\n",
            "Epoch [3/10], Step [10400/12500], Loss: 0.7078\n",
            "Epoch [3/10], Step [10600/12500], Loss: 0.6920\n",
            "Epoch [3/10], Step [10800/12500], Loss: 0.7084\n",
            "Epoch [3/10], Step [11000/12500], Loss: 0.7169\n",
            "Epoch [3/10], Step [11200/12500], Loss: 0.6986\n",
            "Epoch [3/10], Step [11400/12500], Loss: 0.6840\n",
            "Epoch [3/10], Step [11600/12500], Loss: 0.7644\n",
            "Epoch [3/10], Step [11800/12500], Loss: 0.7204\n",
            "Epoch [3/10], Step [12000/12500], Loss: 0.6139\n",
            "Epoch [3/10], Step [12200/12500], Loss: 0.7257\n",
            "Epoch [3/10], Step [12400/12500], Loss: 0.6394\n",
            "Epoch [4/10], Step [200/12500], Loss: 0.5095\n",
            "Epoch [4/10], Step [400/12500], Loss: 0.5343\n",
            "Epoch [4/10], Step [600/12500], Loss: 0.5085\n",
            "Epoch [4/10], Step [800/12500], Loss: 0.4887\n",
            "Epoch [4/10], Step [1000/12500], Loss: 0.5113\n",
            "Epoch [4/10], Step [1200/12500], Loss: 0.4741\n",
            "Epoch [4/10], Step [1400/12500], Loss: 0.4536\n",
            "Epoch [4/10], Step [1600/12500], Loss: 0.4421\n",
            "Epoch [4/10], Step [1800/12500], Loss: 0.5144\n",
            "Epoch [4/10], Step [2000/12500], Loss: 0.5020\n",
            "Epoch [4/10], Step [2200/12500], Loss: 0.4829\n",
            "Epoch [4/10], Step [2400/12500], Loss: 0.5240\n",
            "Epoch [4/10], Step [2600/12500], Loss: 0.5048\n",
            "Epoch [4/10], Step [2800/12500], Loss: 0.5494\n",
            "Epoch [4/10], Step [3000/12500], Loss: 0.4975\n",
            "Epoch [4/10], Step [3200/12500], Loss: 0.4948\n",
            "Epoch [4/10], Step [3400/12500], Loss: 0.5225\n",
            "Epoch [4/10], Step [3600/12500], Loss: 0.5306\n",
            "Epoch [4/10], Step [3800/12500], Loss: 0.5105\n",
            "Epoch [4/10], Step [4000/12500], Loss: 0.5290\n",
            "Epoch [4/10], Step [4200/12500], Loss: 0.5251\n",
            "Epoch [4/10], Step [4400/12500], Loss: 0.5103\n",
            "Epoch [4/10], Step [4600/12500], Loss: 0.5458\n",
            "Epoch [4/10], Step [4800/12500], Loss: 0.4569\n",
            "Epoch [4/10], Step [5000/12500], Loss: 0.5682\n",
            "Epoch [4/10], Step [5200/12500], Loss: 0.4816\n",
            "Epoch [4/10], Step [5400/12500], Loss: 0.4873\n",
            "Epoch [4/10], Step [5600/12500], Loss: 0.5387\n",
            "Epoch [4/10], Step [5800/12500], Loss: 0.5131\n",
            "Epoch [4/10], Step [6000/12500], Loss: 0.5118\n",
            "Epoch [4/10], Step [6200/12500], Loss: 0.5070\n",
            "Epoch [4/10], Step [6400/12500], Loss: 0.5248\n",
            "Epoch [4/10], Step [6600/12500], Loss: 0.5636\n",
            "Epoch [4/10], Step [6800/12500], Loss: 0.5287\n",
            "Epoch [4/10], Step [7000/12500], Loss: 0.4826\n",
            "Epoch [4/10], Step [7200/12500], Loss: 0.4894\n",
            "Epoch [4/10], Step [7400/12500], Loss: 0.5350\n",
            "Epoch [4/10], Step [7600/12500], Loss: 0.5163\n",
            "Epoch [4/10], Step [7800/12500], Loss: 0.5011\n",
            "Epoch [4/10], Step [8000/12500], Loss: 0.4844\n",
            "Epoch [4/10], Step [8200/12500], Loss: 0.5280\n",
            "Epoch [4/10], Step [8400/12500], Loss: 0.5310\n",
            "Epoch [4/10], Step [8600/12500], Loss: 0.5700\n",
            "Epoch [4/10], Step [8800/12500], Loss: 0.4797\n",
            "Epoch [4/10], Step [9000/12500], Loss: 0.5887\n",
            "Epoch [4/10], Step [9200/12500], Loss: 0.6085\n",
            "Epoch [4/10], Step [9400/12500], Loss: 0.5681\n",
            "Epoch [4/10], Step [9600/12500], Loss: 0.5882\n",
            "Epoch [4/10], Step [9800/12500], Loss: 0.5120\n",
            "Epoch [4/10], Step [10000/12500], Loss: 0.4833\n",
            "Epoch [4/10], Step [10200/12500], Loss: 0.5001\n",
            "Epoch [4/10], Step [10400/12500], Loss: 0.5162\n",
            "Epoch [4/10], Step [10600/12500], Loss: 0.4442\n",
            "Epoch [4/10], Step [10800/12500], Loss: 0.4867\n",
            "Epoch [4/10], Step [11000/12500], Loss: 0.5626\n",
            "Epoch [4/10], Step [11200/12500], Loss: 0.5662\n",
            "Epoch [4/10], Step [11400/12500], Loss: 0.5096\n",
            "Epoch [4/10], Step [11600/12500], Loss: 0.4789\n",
            "Epoch [4/10], Step [11800/12500], Loss: 0.5201\n",
            "Epoch [4/10], Step [12000/12500], Loss: 0.4887\n",
            "Epoch [4/10], Step [12200/12500], Loss: 0.5236\n",
            "Epoch [4/10], Step [12400/12500], Loss: 0.5548\n",
            "Epoch [5/10], Step [200/12500], Loss: 0.3098\n",
            "Epoch [5/10], Step [400/12500], Loss: 0.3003\n",
            "Epoch [5/10], Step [600/12500], Loss: 0.2607\n",
            "Epoch [5/10], Step [800/12500], Loss: 0.2822\n",
            "Epoch [5/10], Step [1000/12500], Loss: 0.2538\n",
            "Epoch [5/10], Step [1200/12500], Loss: 0.2913\n",
            "Epoch [5/10], Step [1400/12500], Loss: 0.3080\n",
            "Epoch [5/10], Step [1600/12500], Loss: 0.2480\n",
            "Epoch [5/10], Step [1800/12500], Loss: 0.3362\n",
            "Epoch [5/10], Step [2000/12500], Loss: 0.2792\n",
            "Epoch [5/10], Step [2200/12500], Loss: 0.2576\n",
            "Epoch [5/10], Step [2400/12500], Loss: 0.2857\n",
            "Epoch [5/10], Step [2600/12500], Loss: 0.3026\n",
            "Epoch [5/10], Step [2800/12500], Loss: 0.2624\n",
            "Epoch [5/10], Step [3000/12500], Loss: 0.3376\n",
            "Epoch [5/10], Step [3200/12500], Loss: 0.2806\n",
            "Epoch [5/10], Step [3400/12500], Loss: 0.3060\n",
            "Epoch [5/10], Step [3600/12500], Loss: 0.3346\n",
            "Epoch [5/10], Step [3800/12500], Loss: 0.3581\n",
            "Epoch [5/10], Step [4000/12500], Loss: 0.3251\n",
            "Epoch [5/10], Step [4200/12500], Loss: 0.3123\n",
            "Epoch [5/10], Step [4400/12500], Loss: 0.3041\n",
            "Epoch [5/10], Step [4600/12500], Loss: 0.3409\n",
            "Epoch [5/10], Step [4800/12500], Loss: 0.3444\n",
            "Epoch [5/10], Step [5000/12500], Loss: 0.3281\n",
            "Epoch [5/10], Step [5200/12500], Loss: 0.3773\n",
            "Epoch [5/10], Step [5400/12500], Loss: 0.3063\n",
            "Epoch [5/10], Step [5600/12500], Loss: 0.3079\n",
            "Epoch [5/10], Step [5800/12500], Loss: 0.3333\n",
            "Epoch [5/10], Step [6000/12500], Loss: 0.3336\n",
            "Epoch [5/10], Step [6200/12500], Loss: 0.3195\n",
            "Epoch [5/10], Step [6400/12500], Loss: 0.3138\n",
            "Epoch [5/10], Step [6600/12500], Loss: 0.3143\n",
            "Epoch [5/10], Step [6800/12500], Loss: 0.3382\n",
            "Epoch [5/10], Step [7000/12500], Loss: 0.3409\n",
            "Epoch [5/10], Step [7200/12500], Loss: 0.3174\n",
            "Epoch [5/10], Step [7400/12500], Loss: 0.3133\n",
            "Epoch [5/10], Step [7600/12500], Loss: 0.3350\n",
            "Epoch [5/10], Step [7800/12500], Loss: 0.2831\n",
            "Epoch [5/10], Step [8000/12500], Loss: 0.2892\n",
            "Epoch [5/10], Step [8200/12500], Loss: 0.3770\n",
            "Epoch [5/10], Step [8400/12500], Loss: 0.3551\n",
            "Epoch [5/10], Step [8600/12500], Loss: 0.2892\n",
            "Epoch [5/10], Step [8800/12500], Loss: 0.3624\n",
            "Epoch [5/10], Step [9000/12500], Loss: 0.3459\n",
            "Epoch [5/10], Step [9200/12500], Loss: 0.3569\n",
            "Epoch [5/10], Step [9400/12500], Loss: 0.3822\n",
            "Epoch [5/10], Step [9600/12500], Loss: 0.3298\n",
            "Epoch [5/10], Step [9800/12500], Loss: 0.3489\n",
            "Epoch [5/10], Step [10000/12500], Loss: 0.3210\n",
            "Epoch [5/10], Step [10200/12500], Loss: 0.3023\n",
            "Epoch [5/10], Step [10400/12500], Loss: 0.3353\n",
            "Epoch [5/10], Step [10600/12500], Loss: 0.3680\n",
            "Epoch [5/10], Step [10800/12500], Loss: 0.3512\n",
            "Epoch [5/10], Step [11000/12500], Loss: 0.3562\n",
            "Epoch [5/10], Step [11200/12500], Loss: 0.3768\n",
            "Epoch [5/10], Step [11400/12500], Loss: 0.3459\n",
            "Epoch [5/10], Step [11600/12500], Loss: 0.3917\n",
            "Epoch [5/10], Step [11800/12500], Loss: 0.3723\n",
            "Epoch [5/10], Step [12000/12500], Loss: 0.4118\n",
            "Epoch [5/10], Step [12200/12500], Loss: 0.3520\n",
            "Epoch [5/10], Step [12400/12500], Loss: 0.3254\n",
            "Epoch [6/10], Step [200/12500], Loss: 0.1630\n",
            "Epoch [6/10], Step [400/12500], Loss: 0.1508\n",
            "Epoch [6/10], Step [600/12500], Loss: 0.1528\n",
            "Epoch [6/10], Step [800/12500], Loss: 0.1378\n",
            "Epoch [6/10], Step [1000/12500], Loss: 0.1765\n",
            "Epoch [6/10], Step [1200/12500], Loss: 0.1793\n",
            "Epoch [6/10], Step [1400/12500], Loss: 0.1478\n",
            "Epoch [6/10], Step [1600/12500], Loss: 0.1432\n",
            "Epoch [6/10], Step [1800/12500], Loss: 0.2183\n",
            "Epoch [6/10], Step [2000/12500], Loss: 0.1292\n",
            "Epoch [6/10], Step [2200/12500], Loss: 0.1485\n",
            "Epoch [6/10], Step [2400/12500], Loss: 0.1885\n",
            "Epoch [6/10], Step [2600/12500], Loss: 0.1863\n",
            "Epoch [6/10], Step [2800/12500], Loss: 0.1811\n",
            "Epoch [6/10], Step [3000/12500], Loss: 0.1608\n",
            "Epoch [6/10], Step [3200/12500], Loss: 0.1493\n",
            "Epoch [6/10], Step [3400/12500], Loss: 0.1719\n",
            "Epoch [6/10], Step [3600/12500], Loss: 0.1925\n",
            "Epoch [6/10], Step [3800/12500], Loss: 0.2196\n",
            "Epoch [6/10], Step [4000/12500], Loss: 0.1975\n",
            "Epoch [6/10], Step [4200/12500], Loss: 0.2039\n",
            "Epoch [6/10], Step [4400/12500], Loss: 0.1814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "kghLkUN7bpYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/COMPUTATIONALINTELLIGENCEPERSONAL\n",
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "7gXzbHG7cmvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements_gpu.txt  # or requirements.txt if you prefer\n",
        "!pip install deap"
      ],
      "metadata": {
        "id": "ripdCzJ3crKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python nsgaII.py"
      ],
      "metadata": {
        "id": "PZEj8VqscubG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"figures\"))"
      ],
      "metadata": {
        "id": "qbjD7l-FcyW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edd6d612"
      },
      "source": [
        "import os\n",
        "if not os.path.exists('figures'):\n",
        "    os.makedirs('figures')\n",
        "    print(\"Directory 'figures' created.\")\n",
        "else:\n",
        "    print(\"Directory 'figures' already exists.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/COMPUTATIONALINTELLIGENCEPERSONAL\n",
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "gDXEALzddQz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements_gpu.txt  # or requirements.txt\n",
        "!pip install deap"
      ],
      "metadata": {
        "id": "n9yjv7ekdTXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python nsgaII.py"
      ],
      "metadata": {
        "id": "attRnu7ldXtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"figures\"))"
      ],
      "metadata": {
        "id": "UjvNI8X7dcQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python nsgaII.py"
      ],
      "metadata": {
        "id": "bjDI7YgaeFyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/COMPUTATIONALINTELLIGENCEPERSONAL\n",
        "!python nsgaII.py"
      ],
      "metadata": {
        "id": "w6QX4wIue6H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/COMPUTATIONALINTELLIGENCEPERSONAL\n",
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "O8XTQcNIfHqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python nsgaII.py"
      ],
      "metadata": {
        "id": "K6_lkpcGfKo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"figures\"))"
      ],
      "metadata": {
        "id": "pcS6TFTMfPhe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}